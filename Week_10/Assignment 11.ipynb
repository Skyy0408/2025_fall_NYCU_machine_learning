{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9df1e02-e867-4737-8960-a26ff28cbf03",
   "metadata": {},
   "source": [
    "# Problem 1\n",
    "Week 1: \n",
    "\n",
    "<figure id=\"Week_1.png\">\n",
    "    <img src=\"Week_1.png\" alt=\"Week_1\" style=\"width: 70%;\">\n",
    "    <figcaption><b>Figure 1</b>: The Problem in Week 1.</figcaption>\n",
    "</figure>\n",
    "\n",
    "I've already answered it in the same assignment, by \n",
    "\n",
    "(a) See: [What Happened When Gradient is almost zero?](https://docs.google.com/presentation/d/1siUFXARYRpNiMeSRwgFbt7mZVjkMPhR5od09w0Z8xaU/edit?slide=id.g31470fd33a_0_33\\#slide=id.g31470fd33a_0_33)\n",
    "\n",
    "(b) See: [【機器學習2021】類神經網路訓練不起來怎麼辦 (二)： 批次 (batch) 與動量 (momentum) 22:37}](https://www.youtube.com/watch?v=zzbr1h9sF54&list=PLJV_el3uVTsMhtt7_Y6sgTHGHp1Vb2P2J&index=5)\n",
    "\n",
    "(c) See: [【機器學習2021】類神經網路訓練不起來怎麼辦 (三)：自動調整學習速率 (Learning Rate) 00:00}](https://www.youtube.com/watch?v=HYUXEeh3kwY&list=PLJV_el3uVTsMhtt7_Y6sgTHGHp1Vb2P2J&index=7)\n",
    "\n",
    "Week 2:\n",
    "I was wondering how to fix the problem(the oscillation on the both sides, which is called the Runge Phenomenon) in Figure 10 below. I've tried to change the way I select the data but it doesn't work.\n",
    "\n",
    "<figure id=\"Fourier Learning rate:0.01 Layer:3 Epoch:20000 Datanum:10001\">\n",
    "    <img src=\"Fourier_0.01_20000_10001_3.png\" alt=\"Fourier 3 Layers\" style=\"width: 70%;\">\n",
    "    <figcaption><b>Figure 10</b>: Fourier Learning rate:0.01 Layer:3 Epoch:20000 Datanum:10001.</figcaption>\n",
    "</figure>\n",
    "\n",
    "Week 3: None.\n",
    "\n",
    "Week 4: None.\n",
    "\n",
    "Week 5: None.\n",
    "\n",
    "Week 6: How can the max error be reduced without incorporating additional features like altitude or humidity?\n",
    "\n",
    "Analysis: Based on the results, even the best-performing model exhibits a maximum error of nearly 9°C. This suggests we've reached the performance limit of what can be achieved with the current feature set. In my opinion, it's likely impossible to develop a \"perfect\" model with such a low max error without providing it with more informative data. The fundamental limitation appears to be the absence of crucial predictive variables, not the model architecture itself.\n",
    "\n",
    "Week 7: Abou Explicit Score Matching(ESM) and Implicit Score Matching(ISM), \n",
    "1. Does there exist other score function?\n",
    "2. What about its efficiency?\n",
    "\n",
    "Week 8:\n",
    "I have attended a speech which mentioned the Brownian Motion and Heat Equation, also, it is used in the financial field. However, there are planty of unexpected incidents happened in recent year, is it also suitable to use Brownian Motion to explain or estimate the stock market?\n",
    "\n",
    "Week 9: None\n",
    "\n",
    "Week 10: If every stochastic diffusion process has a corresponding probability flow ODE that preserves its marginal distributions, does this mean randomness is fundamentally unnecessary for generative modeling?\n",
    "\n",
    "# Problem 2\n",
    "A major limitation of traditional reinforcement learning is its heavy reliance on extensive interactions with the real environment. For safety-critical applications such as autonomous driving, this requirement becomes impractical: real-world interaction is slow, expensive, and often dangerous, even if the learned policy can eventually reach a high success rate(by [\n",
    "Model-Predictive Policy Learning with Uncertainty Regularization for Driving in Dense Traffic](https://openreview.net/forum?id=HygQBn0cYm)). To bypass these issues, my project adopts a model-predictive perspective and leverages a world model to replace most real-world interactions with simulated rollouts.\n",
    "\n",
    "Specifically, I focus on reproducing the DFM-KM MPC method from [Separating the World Model and Ego Models for Self-Driving](https://arxiv.org/abs/2204.07184). This framework separates the environment dynamics and the ego-vehicle dynamics: the ego state is predicted by a differentiable kinematic model, while a stochastic environment model predicts other vehicles. During planning, gradients are propagated only through the ego-model, allowing stable optimization without requiring the environment model to be differentiable. The cost function is implemented with differentiable masks, making the system interpretable and enabling us to verify whether the model learns the “right” behaviors.\n",
    "\n",
    "The goal of this project is to first reproduce the DFM-KM MPC pipeline and evaluate whether we can achieve performance comparable to the results reported in the original paper. This serves as a simplified and feasible first step toward building safer model-based decision-making systems for autonomous driving."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
