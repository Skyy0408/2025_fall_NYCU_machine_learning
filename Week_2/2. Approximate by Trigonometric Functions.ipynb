{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "703afac8-b8e4-40cb-aa4e-34648e543847",
   "metadata": {},
   "source": [
    "# Approximate by Trigonometric Functions\n",
    "My understanding of polynomial approximation is analogous to a Taylor series, which led me to consider a Fourier series-like approach.\n",
    "\n",
    "In the other words, I just try to use Trigonometric Functions to deal with this problem.\n",
    "\n",
    "Before I start, note that the Runge function is an even function:\n",
    "\n",
    "$$\n",
    "f(-x)=\\dfrac{1}{1+25(-x)^2}=\\dfrac{1}{1+25x^2}=f(x)\n",
    "$$\n",
    "\n",
    "Thus, I just use the cosine functions as my hypothesis.\n",
    "\n",
    "The main proram is shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b084165-c1ab-4b13-acc7-281f2ce331bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "jax.config.update(\"jax_enable_x64\", True)\n",
    "\n",
    "# The Runge Function\n",
    "def f(x):\n",
    "    return 1/(1+25*x**2)\n",
    "\n",
    "# Hyperparameters\n",
    "learning_rate = 0.01\n",
    "epochs = 20000\n",
    "datanum = 1001\n",
    "\n",
    "# Data\n",
    "x_train = jnp.linspace(-1.0, 1.0, datanum)\n",
    "y_train = f(x_train)\n",
    "\n",
    "key=jax.random.PRNGKey(0)\n",
    "key, w1_key, w2_key, b_key = jax.random.split(key, 4)\n",
    "params = {\n",
    "    'w1': jax.random.normal(w1_key, (1, 16)), \n",
    "    'w2': jax.random.normal(w2_key, (16, 1)), \n",
    "    'b': jax.random.normal(b_key, (1,))\n",
    "}\n",
    "\n",
    "# Construct the Trigonometric Model\n",
    "def trigonometric_model(params, x):\n",
    "    x = x.reshape(-1, 1)\n",
    "    hidden = jnp.cos(x @ params['w1'])\n",
    "    return hidden @ params['w2'] + params['b']\n",
    "\n",
    "def loss_fn(params, x, y):\n",
    "    predictions = trigonometric_model(params, x).squeeze() \n",
    "    return jnp.mean((predictions - y)**2)\n",
    "loss_history = []\n",
    "\n",
    "@jax.jit\n",
    "# Gradient Descent\n",
    "def update_step(params, x, y, learning_rate):\n",
    "    grads = jax.grad(loss_fn)(params, x, y)\n",
    "    return jax.tree.map(lambda p, g: p - learning_rate * g, params, grads)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    params = update_step(params, x_train, y_train, learning_rate)\n",
    "    \n",
    "    if epoch % 1000 == 0:\n",
    "        loss = loss_fn(params, x_train, y_train)\n",
    "        loss_history.append(loss)\n",
    "        print(f\"Epoch {epoch}, Loss: {loss:.6f}\")\n",
    "        \n",
    "x_plot = jnp.linspace(-1, 1, 500)\n",
    "y_true = f(x_plot)\n",
    "y_pred = trigonometric_model(params, x_plot).squeeze()\n",
    "final_mse = loss_fn(params, x_train, y_train)\n",
    "max_error = jnp.max(jnp.abs(trigonometric_model(params, x_train).squeeze() - y_train))\n",
    "\n",
    "# Result\n",
    "print(\"\\n--- Final Result ---\")\n",
    "print(f\"Final MSE: {final_mse:.6f}\")\n",
    "print(f\"Final Max Error: {max_error:.6f}\")\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(x_plot, y_true, label='True Runge Function', color='blue')\n",
    "plt.plot(x_plot, y_pred, label='Neural Network Prediction', color='red', linestyle='--')\n",
    "plt.scatter(x_train, y_train, s=10, color='gray', alpha=0.5, label='Training Data')\n",
    "plt.title('Function Approximation')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('f(x)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(0, epochs, 1000), loss_history)\n",
    "plt.title('Training Loss Curve')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Mean Squared Error Loss')\n",
    "plt.yscale('log') \n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8acfab5-1327-4a3d-8625-65d3cc09c6e1",
   "metadata": {},
   "source": [
    "```text\n",
    "--- Final Result ---\n",
    "Final MSE: 0.014785\n",
    "Final Max Error: 0.311562\n",
    "```\n",
    "<figure id=\"Fourier Learning rate:0.01 Layer:1 Epoch:20000 Datanum:1001\">\n",
    "    <img src=\"Fourier_0.01_20000_1001.png\" alt=\"Fourier 1 Layer\" style=\"width: 70%;\">\n",
    "    <figcaption><b>Figure 7</b>: Fourier Learning rate:0.01 Layer:1 Epoch:20000 Datanum:1001.</figcaption>\n",
    "</figure>\n",
    "\n",
    "```text\n",
    "--- Final Result ---\n",
    "Final MSE: 0.014769\n",
    "Final Max Error: 0.311453\n",
    "```\n",
    "\n",
    "<figure id=\"Fourier Learning rate:0.01 Layer:1 Epoch:20000 Datanum:10001\">\n",
    "    <img src=\"Fourier_0.01_20000_10001.png\" alt=\"Fourier 1 Layer\" style=\"width: 70%;\">\n",
    "    <figcaption><b>Figure 8</b>: Fourier Learning rate:0.01 Layer:1 Epoch:20000 Datanum:10001.</figcaption>\n",
    "</figure>\n",
    "\n",
    "I found that the shape did not match my expectations as well as I had imagined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f150efa-0797-4041-8ecf-e30675d662ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "jax.config.update(\"jax_enable_x64\", True)\n",
    "\n",
    "# The Runge Function\n",
    "def f(x):\n",
    "    return 1/(1+25*x**2)\n",
    "\n",
    "# Hyperparameters\n",
    "learning_rate = 0.01\n",
    "epochs = 20000\n",
    "datanum = 10001\n",
    "\n",
    "# Data\n",
    "x_train = jnp.linspace(-1.0, 1.0, datanum)\n",
    "y_train = f(x_train)\n",
    "\n",
    "key=jax.random.PRNGKey(0)\n",
    "keys = jax.random.split(key, 7)\n",
    "params = {\n",
    "    'w1': jax.random.normal(keys[0], (1, 16)),\n",
    "    \n",
    "    'w2': jax.random.normal(keys[1], (16, 16)),\n",
    "    'b2': jax.random.normal(keys[2], (16,)),\n",
    "\n",
    "    'w3': jax.random.normal(keys[3], (16, 16)),                                                                   # Added\n",
    "    'b3': jax.random.normal(keys[4], (16,)),                                                                      # Added\n",
    "\n",
    "    'w4': jax.random.normal(keys[5], (16, 1)),                                                                    # Added\n",
    "    'b4': jax.random.normal(keys[6], (1,))                                                                        # Added\n",
    "}\n",
    "\n",
    "# Construct the Trigonometric Model\n",
    "def deep_trigonometric_model(params, x):\n",
    "    x = x.reshape(-1, 1)\n",
    "    features = jnp.cos(x @ params['w1'])\n",
    "    hidden1 = jnp.cos(features @ params['w2'] + params['b2'])\n",
    "    hidden2 = jnp.cos(hidden1 @ params['w3'] + params['b3'])\n",
    "    output = hidden2 @ params['w4'] + params['b4']\n",
    "    return output\n",
    "\n",
    "def loss_fn(params, x, y):\n",
    "    predictions = deep_trigonometric_model(params, x).squeeze() \n",
    "    return jnp.mean((predictions - y)**2)\n",
    "loss_history = []\n",
    "\n",
    "@jax.jit\n",
    "# Gradient Descent\n",
    "def update_step(params, x, y, learning_rate):\n",
    "    grads = jax.grad(loss_fn)(params, x, y)\n",
    "    return jax.tree.map(lambda p, g: p - learning_rate * g, params, grads)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    params = update_step(params, x_train, y_train, learning_rate)\n",
    "    \n",
    "    if epoch % 1000 == 0:\n",
    "        loss = loss_fn(params, x_train, y_train)\n",
    "        loss_history.append(loss)\n",
    "        print(f\"Epoch {epoch}, Loss: {loss:.6f}\")\n",
    "        \n",
    "x_plot = jnp.linspace(-1, 1, 500)\n",
    "y_true = f(x_plot)\n",
    "y_pred = deep_trigonometric_model(params, x_plot).squeeze()\n",
    "y_pred_train = deep_trigonometric_model(params, x_train).squeeze()\n",
    "final_mse = jnp.mean((y_pred_train - y_train)**2)\n",
    "max_error = jnp.max(jnp.abs(y_pred_train - y_train))\n",
    "\n",
    "# Result\n",
    "print(\"\\n--- Final Result ---\")\n",
    "print(f\"Final MSE: {final_mse:.6f}\")\n",
    "print(f\"Final Max Error: {max_error:.6f}\")\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(x_plot, y_true, label='True Runge Function', color='blue')\n",
    "plt.plot(x_plot, y_pred, label='Neural Network Prediction', color='red', linestyle='--')\n",
    "plt.scatter(x_train, y_train, s=10, color='gray', alpha=0.5, label='Training Data')\n",
    "plt.title('Function Approximation')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('f(x)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(0, epochs, 1000), loss_history)\n",
    "plt.title('Training Loss Curve')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Mean Squared Error Loss')\n",
    "plt.yscale('log') \n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb64086-71cb-4a97-b42b-602d56e9dc49",
   "metadata": {},
   "source": [
    "```text\n",
    "--- Final Result ---\n",
    "Final MSE: 0.001284\n",
    "Final Max Error: 0.091240\n",
    "```\n",
    "\n",
    "<figure id=\"Fourier Learning rate:0.01 Layer:2 Epoch:20000 Datanum:10001\">\n",
    "    <img src=\"Fourier_0.01_20000_10001_2.png\" alt=\"Fourier 2 Layers\" style=\"width: 70%;\">\n",
    "    <figcaption><b>Figure 9</b>: Fourier Learning rate:0.01 Layer:2 Epoch:20000 Datanum:10001.</figcaption>\n",
    "</figure>\n",
    "\n",
    "This matched my assumption. Although a strange oscillation appeared on the right-hand side, this result encouraged me to add another hidden layer.\n",
    "\n",
    "```text\n",
    "--- Final Result ---\n",
    "Final MSE: 0.000074\n",
    "Final Max Error: 0.022620\n",
    "```\n",
    "\n",
    "<figure id=\"Fourier Learning rate:0.01 Layer:3 Epoch:20000 Datanum:10001\">\n",
    "    <img src=\"Fourier_0.01_20000_10001_3.png\" alt=\"Fourier 3 Layers\" style=\"width: 70%;\">\n",
    "    <figcaption><b>Figure 10</b>: Fourier Learning rate:0.01 Layer:3 Epoch:20000 Datanum:10001.</figcaption>\n",
    "</figure>\n",
    "\n",
    "I found that the learning rate I had set was too large for this model, and it made the gradient \"explode\". \n",
    "\n",
    "Thus, I decrease the learning rate.\n",
    "```text\n",
    "--- Final Result ---\n",
    "Final MSE: 0.000265\n",
    "Final Max Error: 0.076985\n",
    "```\n",
    "\n",
    "<figure id=\"Fourier Learning rate:0.001 Layer:3 Epoch:20000 Datanum:10001\">\n",
    "    <img src=\"Fourier_0.001_20000_10001_3.png\" alt=\"Fourier 3 Layers\" style=\"width: 70%;\">\n",
    "    <figcaption><b>Figure 11</b>: Fourier Learning rate:0.001 Layer:3 Epoch:20000 Datanum:10001.</figcaption>\n",
    "</figure>\n",
    "\n",
    "```text\n",
    "--- Final Result ---\n",
    "Final MSE: 0.003896\n",
    "Final Max Error: 0.226449\n",
    "```\n",
    "\n",
    "<figure id=\"Fourier Learning rate:0.0001 Layer:3 Epoch:20000 Datanum:10001\">\n",
    "    <img src=\"Fourier_0.0001_20000_10001_3.png\" alt=\"Fourier 3 Layers\" style=\"width: 70%;\">\n",
    "    <figcaption><b>Figure 12</b>: Fourier Learning rate:0.0001 Layer:3 Epoch:20000 Datanum:10001.</figcaption>\n",
    "</figure>\n",
    "\n",
    "The middle part almost match the shape of the target, however, it oscillates severely in the both sides, especially for the lowest learning rate, which is shown in Figure 12.\n",
    "\n",
    "After this, I just removed one layer, which means that we have 2 layers hidden now, and try to give it more data.\n",
    "\n",
    "```text\n",
    "--- Final Result ---\n",
    "Final MSE: 0.000896\n",
    "Final Max Error: 0.081194\n",
    "```\n",
    "\n",
    "<figure id=\"Fourier Learning rate:0.01 Layer:2 Epoch:40000 Datanum:1000001\">\n",
    "    <img src=\"Fourier_0.01_40000_1000001_2.png\" alt=\"Fourier 2 Layers Random with huge data\" style=\"width: 70%;\">\n",
    "    <figcaption><b>Figure 13</b>: Fourier Learning rate:0.01 Layer:2 Epoch:40000 Datanum:1000001.</figcaption>\n",
    "</figure>\n",
    "\n",
    "```text\n",
    "--- Final Result ---\n",
    "Final MSE: 0.002676\n",
    "Final Max Error: 0.135742\n",
    "```\n",
    "\n",
    "<figure id=\"Fourier Learning rate:0.001 Layer:2 Epoch:40000 Datanum:1000001\">\n",
    "    <img src=\"Fourier_0.001_40000_1000001_2.png\" alt=\"Fourier 2 Layers Random with huge data\" style=\"width: 70%;\">\n",
    "    <figcaption><b>Figure 14</b>: Fourier Learning rate:0.001 Layer:2 Epoch:40000 Datanum:1000001.</figcaption>\n",
    "</figure>\n",
    "\n",
    "I considered this a form of overfitting; however, the better performance in the central region was undeniable.\n",
    "\n",
    "Therefore, I try to adjust the way I select the data.\n",
    "```python\n",
    "x_center = jnp.linspace(-0.5, 0.5, datanum//2)\n",
    "x_left = jnp.linspace(-1.0, -0.5, datanum//4)\n",
    "x_right = jnp.linspace(0.5, 1.0, datanum//4)\n",
    "x_train = jnp.concatenate([x_center, x_left, x_right])\n",
    "```\n",
    "\n",
    "```text\n",
    "--- Final Result ---\n",
    "Final MSE: 0.001097\n",
    "Final Max Error: 0.093484\n",
    "```\n",
    "<figure id=\"Fourier Learning rate:0.01 Layer:3 Epoch:20000 Datanum:10000\">\n",
    "    <img src=\"Fourier_0.01_20000_10000_3_s.png\" alt=\"Fourier 3 Layers\" style=\"width: 70%;\">\n",
    "    <figcaption><b>Figure 10'</b>: Fourier Learning rate:0.01 Layer:3 Epoch:20000 Datanum:10000.</figcaption>\n",
    "</figure>\n",
    "\n",
    "In conclusion, even if the graph in Figure 10 almost match the function we want to approach, but we can also see the osscilations in both sides.\n",
    "\n",
    "Hence, I decided to try another approach using the sigmoid function, which we learned in class."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
